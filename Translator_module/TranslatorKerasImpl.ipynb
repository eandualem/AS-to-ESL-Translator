{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"TranslatorKerasImpl.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gyHobCdpY4oM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596114263264,"user_tz":-180,"elapsed":1155,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}},"outputId":"4f8e919d-c012-4084-a005-f3a711e020e9"},"source":["''' \n","  This is to create sym links of file needed in the notebook\n","  used for devlopment only!!!\n","'''\n","# !ln -s ./drive/My\\ Drive/HornMorph/\n","# !ln -s ./drive/My\\ Drive/AMh2ESLTest/raw_data/\n","# !ln -s ./drive/My\\ Drive/AMh2ESLTest/processed_data/\n","# !ln -s ./drive/My\\ Drive/AMh2ESLTest/embedding_checkpoints/\n","# !ln -s ./drive/My\\ Drive/AMh2ESLTest/translator_helper.py\n","# !ln -s ./drive/My\\ Drive/AMh2ESLTest/preprocess_util.py\n","# # !ln -s ./drive/My\\ Drive/AMh2ESLTest/word2vec_helper.py\n","# !ln -s ./drive/My\\ Drive/AMh2ESLTest/amh_vocab_mapping.p\n","# !ln -s ./drive/My\\ Drive/AMh2ESLTest/preprocssed_data.p"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' \\n  This is to create sym links of file needed in the notebook\\n  used for devlopment only!!!\\n'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"-I5FuBphquhu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596114266610,"user_tz":-180,"elapsed":4482,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}},"outputId":"0a6f0f0c-6b93-4c77-ee74-a6a45618164d"},"source":["import translator_helper as helper\n","import os\n","import preprocess_util as putil\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow.compat.v1 as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","if not tf.test.gpu_device_name():\n","    print('No GPU found. Please use a GPU to train your neural network.')\n","else:\n","    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2.2.0\n","Default GPU Device: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HYPQftz-bJv6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114266611,"user_tz":-180,"elapsed":4472,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["source_path = \"./raw_data/parallel_sentence_corpus/amh2.txt\"\n","target_path = \"./raw_data/parallel_sentence_corpus/amh2.txt\"\n","source_vocab_mapping = \"./amh_vocab_mapping.p\"\n","target_vocab_mapping = \"./amh_vocab_mapping.p\"\n","PREPROCESS_SAVE_PATH = \"preprocssed_data.p\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOQqQaxnYKB_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114267118,"user_tz":-180,"elapsed":4975,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["#loading src language vlocabulary and target language vocabulay\n","src_int_to_vocab, src_vocab_to_int = putil.load_file(source_vocab_mapping)\n","tgt_int_to_vocab, tgt_vocab_to_int = putil.load_file(target_vocab_mapping)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"gTtA5yHMYNmz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596114267644,"user_tz":-180,"elapsed":5497,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}},"outputId":"e52a56a2-8b15-4efc-9acd-0e5f184c8ecf"},"source":["helper.preprocess_and_save(source_path, target_path,\n","                           src_int_to_vocab, src_vocab_to_int,\n","                           tgt_int_to_vocab, tgt_vocab_to_int,\n","                           PREPROCESS_SAVE_PATH)\n","print(\"processed data saved...\")\n","# data is cleaned, indexed and processed!\n","# chekpoint saved"],"execution_count":5,"outputs":[{"output_type":"stream","text":["processed data saved...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sPXFam88KNrm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114267645,"user_tz":-180,"elapsed":5490,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["# loading all processed data\n","# src_int_text: src language sentences\n","(src_int_text, tgt_int_text), (src_vocab_to_int, tgt_vocab_to_int), (src_int_to_vocab, tgt_int_to_vocab)  = helper.load_preprocessed_data(PREPROCESS_SAVE_PATH)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"GiPCsRm_Jg5e","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114267646,"user_tz":-180,"elapsed":5483,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["def load_dataset(src_int_sent, tgt_int_sent, src_pad_id, tgt_pad_id):\n","    max_src_lang = max([len(sen) for sen in src_int_sent])\n","    max_tgt_lang = max([len(sen) for sen in tgt_int_sent]) \n","    #padding every sentence with max length of the longest sentence in the batch\n","    padded_src_sent = tf.keras.preprocessing.sequence.pad_sequences(src_int_sent, \n","                                                                 maxlen=max_src_lang,\n","                                                                 padding='post',\n","                                                                 value= src_pad_id)\n","    padded_tgt_sent = tf.keras.preprocessing.sequence.pad_sequences(tgt_int_sent, \n","                                                                  maxlen=max_tgt_lang, \n","                                                                  padding='post',\n","                                                                  value=tgt_pad_id)\n","    return padded_src_sent, padded_tgt_sent, max_src_lang, max_tgt_lang"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"bX_U5mcLbqJr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114267646,"user_tz":-180,"elapsed":5474,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["def get_embedding_mat(embedding_size, vocab_size, load_path):\n","  embed_graph = tf.Graph()\n","  with embed_graph.as_default():\n","    inputs = tf.compat.v1.placeholder(tf.int32, [None], name='inputs')\n","    labels = tf.compat.v1.placeholder(tf.int32, [None, None], name='labels')\n","    embedding = tf.Variable(tf.compat.v1.truncated_normal([vocab_size, embedding_size]))\n","  with embed_graph.as_default():\n","    saver = tf.compat.v1.train.Saver()\n","\n","  with tf.compat.v1.Session(graph=embed_graph) as sess:\n","    saver.restore(sess, tf.train.latest_checkpoint(load_path))\n","    embed_mat = sess.run(embedding)\n","  #tf.reset_default_graph()\n","  return embed_mat"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"vbcRH_xOquiE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114267647,"user_tz":-180,"elapsed":5467,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["def gru(units):\n","    if tf.test.is_gpu_available():\n","        return tf.keras.layers.CuDNNGRU(units, \n","                                        return_sequences=True, \n","                                        return_state=True, \n","                                        recurrent_initializer='glorot_uniform')\n","    else:\n","        return tf.keras.layers.GRU(units, \n","                                   return_sequences=True, \n","                                   return_state=True, \n","                                   recurrent_activation='sigmoid', \n","                                   recurrent_initializer='glorot_uniform')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEVYv4r8quiI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114267647,"user_tz":-180,"elapsed":5459,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["class Encoder(tf.keras.Model):\n","    def __init__(self, embed_mat, rnn_size, batch_size):\n","        super(Encoder, self).__init__()\n","        self.batch_size = batch_size\n","        self.rnn_size = rnn_size\n","        self.embed_mat = embed_mat\n","        self.gru = gru(self.rnn_size)\n","        \n","    def call(self, enc_input, hidden):\n","        embeded_input = tf.nn.embedding_lookup(self.embed_mat, enc_input)\n","        output, state = self.gru(embeded_input, initial_state = hidden)        \n","        return output, state\n","    \n","    def initialize_hidden_state(self):\n","        return tf.zeros((self.batch_size, self.rnn_size))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Gw109vYwQ0b","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114267648,"user_tz":-180,"elapsed":5450,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["class Decoder(tf.keras.Model):\n","    def __init__(self, tgt_vocab_size, embed_mat, rnn_size, batch_size):\n","        super(Decoder, self).__init__()\n","        self.batch_size = batch_size\n","        self.rnn_size = rnn_size\n","        self.embed_mat = embed_mat\n","        self.gru = gru(self.rnn_size)\n","\n","        self.output_layer = tf.keras.layers.Dense(tgt_vocab_size)\n","        # used for attention \n","        self.W1 = tf.keras.layers.Dense(self.rnn_size)\n","        self.W2 = tf.keras.layers.Dense(self.rnn_size)\n","        self.V = tf.keras.layers.Dense(1)\n","\n","    def call(self, dec_input, hidden, enc_output):\n","        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n","\n","        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n","        attention_weights = tf.nn.softmax(score, axis=1)\n","        \n","        context_vector = attention_weights * enc_output\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","        \n","        dec_embeded_input = tf.nn.embedding_lookup(self.embed_mat, dec_input)\n","        x = tf.concat([tf.expand_dims(context_vector, 1), dec_embeded_input], axis=-1)\n","        \n","        output, state = self.gru(x)        \n","        output = tf.reshape(output, (-1, output.shape[2]))\n","        \n","        x = self.output_layer(output)\n","        return x, state, attention_weights\n","        \n","    def initialize_hidden_state(self):\n","        return tf.zeros((self.batch_sz, self.dec_units))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"05Jx77vWIILO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114267648,"user_tz":-180,"elapsed":5446,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["# preparing the dataset and setting hyper parameters\n","input, target, max_src_len, max_tgt_len = load_dataset(src_int_text, tgt_int_text, src_vocab_to_int['<PAD>'], tgt_vocab_to_int['<PAD>'])\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input, target, test_size=0.1, random_state = 101)\n","\n","BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 256\n","N_BATCH = BUFFER_SIZE//BATCH_SIZE\n","embedding_dim = 256\n","rnn_size = 256\n","lr = 0.001\n","\n","src_vocab_size = len(src_vocab_to_int)\n","vocab_tar_size = len(tgt_vocab_to_int)\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"zn6xkS0OwNfX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1596114268169,"user_tz":-180,"elapsed":5958,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}},"outputId":"47cbf4c4-6d4e-442d-d20f-aa97fbed41ee"},"source":["# loading the embedding matrix\n","src_embed_mat = get_embedding_mat(256, len(src_int_to_vocab),\"embedding_checkpoints\")\n","tgt_embed_mat = get_embedding_mat(256, len(src_int_to_vocab),\"embedding_checkpoints\")\n","\n","# intitalizing the encoder and decoder\n","encoder = Encoder(src_embed_mat, 256, 256)\n","decoder = Decoder(len(tgt_vocab_to_int), tgt_embed_mat, 256, 256)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","INFO:tensorflow:Restoring parameters from embedding_checkpoints/amh_emebdding.ckpt\n","INFO:tensorflow:Restoring parameters from embedding_checkpoints/amh_emebdding.ckpt\n","WARNING:tensorflow:From <ipython-input-9-575eaf6dd96b>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mL0Ppb4GquiK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114268170,"user_tz":-180,"elapsed":5947,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["optimizer = tf.train.AdamOptimizer()\n","def loss_function(real, pred):\n","    mask = 1 - np.equal(real, 0)\n","    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n","    return tf.reduce_mean(loss_)\n"," "],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tp3vkUqItcmU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596114268170,"user_tz":-180,"elapsed":5936,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["checkpoint_dir = './training_checkpoints3'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder) "],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"F48mjJgxquiN","colab_type":"code","colab":{}},"source":["import time\n","EPOCHS = 100\n","for epoch in range(EPOCHS):\n","    start = time.time() \n","    hidden = encoder.initialize_hidden_state()\n","    total_loss = 0 \n","    for (batch, (inp, targ)) in enumerate(dataset):\n","        loss = 0      \n","        with tf.GradientTape() as tape:\n","            enc_output, enc_hidden = encoder(inp, hidden)            \n","            dec_hidden = enc_hidden            \n","            dec_input = tf.expand_dims([tgt_vocab_to_int['<GO>']] * BATCH_SIZE, 1)       \n","\n","            for t in range(0, targ.shape[1]):\n","\n","                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","                loss += loss_function(targ[:, t], predictions)\n","                \n","                dec_input = tf.expand_dims(targ[:, t], 1)\n","        \n","        batch_loss = (loss / int(targ.shape[1]))\n","        total_loss += batch_loss \n","        variables = encoder.variables + decoder.variables  \n","        gradients = tape.gradient(loss, variables) \n","        optimizer.apply_gradients(zip(gradients, variables))\n","        \n","        if batch % 100 == 0:\n","            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n","    checkpoint.save(file_prefix = checkpoint_prefix) \n","    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / N_BATCH))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n","\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xO-ZNuou7meo","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1596114271919,"user_tz":-180,"elapsed":9662,"user":{"displayName":"daniel zelalem","photoUrl":"","userId":"02433931898077353749"}}},"source":["def evaluate(inputs, encoder, decoder, max_length_tgt_to_trans): \n","    inputs = tf.convert_to_tensor(inputs)\n","    result = ''\n","    init_hidden = [tf.zeros((1, 256))]\n","    enc_out, enc_hidden = encoder(inputs, init_hidden)\n","\n","    dec_hidden = enc_hidden\n","    dec_input = tf.expand_dims([tgt_vocab_to_int['<GO>']], 0)\n","\n","    for t in range(max_length_tgt_to_trans): \n","        translation, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_out)  \n","        translation = tf.argmax(translation[0]).numpy()\n","        result += tgt_int_to_vocab[translation] + ' '\n","        if tgt_int_to_vocab[translation] == '<EOS>':\n","            return result\n","        dec_input = tf.expand_dims([translation], 0)\n","\n","    return result"],"execution_count":null,"outputs":[]}]}